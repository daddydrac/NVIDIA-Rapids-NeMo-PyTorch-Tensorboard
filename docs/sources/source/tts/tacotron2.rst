.. _tacotron-2:

Tacotron 2
==========

Model
~~~~~
This model is based on the 
`Tacotron 2 model <https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html>`_
(see also `paper <https://arxiv.org/abs/1712.05884>`_).

Tacotron 2 follows a simple encoder decoder structure that has seen great
success in sequence-to-sequence modeling. NeMo decomposes Tacotron 2 into 4
different Neural Modules:

1. A TextEmbedding Neural Module is a look-up table that is used to convert
   the char id into an embedding space
2. The embedded text is consumed by the Tacotron2Encoder Neural Module.
3. The Tacotron2Decoder Neural Module creates the attention and decoder RNN
   parts of Tacotron 2.
4. Finally, the Tacotron2Postnet takes the output of the Tacotron2Decoder and
   corrects the spectrogram generated by the decoder.

Tips
~~~~
A pseudo metric for audio quality is how well attention is learned. Ideally, we
want a nice clear diagonal alignment. The current models should learn attention
around 20k steps.
